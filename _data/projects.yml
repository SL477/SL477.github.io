- name: Chart the Stock Market
  url: https://stocks.link477.com/
  repository: flask-stockMarketChart
  picture: ChartTheStockMarket
  picture_text: A screenshot of a graph with two stocks jumping up and down in price over time and an input to add in more stocks.
  picture_width: 340
  picture_height: 142.91
  description: |
    This project started as my answer to <a href="https://www.freecodecamp.org/learn/coding-interview-prep/take-home-projects/chart-the-stock-market" target="_blank" rel="noopener noreferrer">FreeCodeCamp Chart the Stock Market</a>.

    Here I created a flask app with web sockets.

    This started life with the JavaScript being in charge of the visualisations in D3. This used a huge amount of code to draw the graph. I then decided to get Python to parse the data and draw the graph, passing the Base64 string back to JavaScript. Jupyter Labs was useful to design the function and then I copied the code out into a python file.

    After quite a few attempts I got the app onto Heroku. This was quite a bit more complicated than I thought it would be. I first found out about the existence of Gunicorn and then how to use it. From this I also found out about using .env files in Python (something that I had done in Node.JS and thought would be a good idea in Python).

    This has since moved to first Railway.app and now render.com. With the JavaScript becoming TypeScript and being in charge of the visualisations using ChartJS.
- name: Predict Health Costs With Regression
  url: https://sl477-fccpredicthealthcostswithregression-main-tdzqp8.streamlitapp.com
  repository: fccPredictHealthCostsWithRegression
  picture: HealthCostPredictions
  picture_text: A screenshot of a dashboard centred around a graph of Predicted vs actual expenses, on the left are various options to give your demographic data and at the bottom is your predicted health costs.
  picture_width: 340
  picture_height: 212.59
  description: |
    This project started as my answer to <a href="https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/linear-regression-health-costs-calculator" target="_blank" rel="noopener noreferrer">FreeCodeCamp Predict Health Costs With Regression</a>.

    Here I created my first Streamlit App, and then discovered how hard it was to put streamlit into a Docker container.

    Here you can see the difference between the model\'s predictions and the actual data. You can then use the controls to predict your health costs.

    I later revisited it to tear out all of the TensorFlow code and replace its model with a Random Forest Regressor
- name: Cat and Dog Image Classifier
  url: https://catvdog.link477.com
  repository: fccCatAndDog
  picture: CatAndDogImageClassifier
  picture_text: There is a picture of a cute cat balancing on top of a door. Above is a button to pick a different image and below is the result of the prediction (cat).
  picture_width: 340
  picture_height: 172.06
  description: |
    This started out as my answer to <a href="https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/cat-and-dog-image-classifier" target="_blank" rel="noopener noreferrer">FreeCodeCamp Cat and Dog Image Classifier</a>.

    I created a Node.JS app which uses TensorFlow.JS with the converted model I made to determine whether the image passed is more likely to be a cat or a dog (with not so great accuracy).
- name: SMS Classifier
  url: /
  repository: flaskSMSClassifier
  picture: SMSClassifier
  picture_text: A table of SMSes with their predictions of spam/ham. Above inputs to enter in new messages.
  picture_width: 340
  picture_height: 258.36
  description: |
    This project originally started as my answer to <a href="https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/neural-network-sms-text-classifier" target="_blank" rel="noopener noreferrer">FreeCodeCamp SMS Classifier</a>.

    In this project I created my first Flask Web App (not including the tutorial I did). Plus my first Docker Container (outside of a tutorial). Originally this used TensorFlow as the machine learning library, but I have now changed this to SciKit Learn.

    In the web app you can test the classification of various texts, the client side JavaScript will post a request to the API which in turn will consult the saved SKLearn model. You can then press the &quot;Add to database&quot; button, this will push it into the local database (a SQLite database inside the Docker container). In the data table at the front end you can flip the classification of messages between spam and ham. You can also delete that entry out of the database.

    Pressing the &quot;Retrain Model&quot; button will cause the Flask server to retrain the Machine Learning model on the data in the SQLite database. It will then test the model against the validation data from FreeCodeCamp (the main data is also from FreeCodeCamp). This may take a little while, it will then save the model in the Docker container and then use that. To build the model manually you can run the file modelmaker.py.
- name: XKCD Reader
  url: https://drive.google.com/drive/folders/1_jtg6b4z-SArgA5KvZkewE4TjUxHe29F?usp=sharing
  repository: /
  picture: XKCDReader
  picture_text: Android Version of the XKCD Reader App, showing the comic of March of the Penguins.
  picture_width: 340
  picture_height: 545.06
  description: |
    My XKCD Reader app, which uses React-Native to render the <a href="https://xkcd.com/" target="_blank" rel="noopener noreferrer">XKCD website</a>.

    The Android APK file (tested on my phone and in the Android emulator) is available at the link above.
- name: PizzaKG
  url: https://link477.com/Pizza_KG/Pizza_KG.html
  repository: Pizza_KG
  picture: SWTKGClassRelationships
  picture_text: A complicated circular graph showing the numbers of different data types in the Knowledge Graph.
  picture_width: 340
  picture_height: 368.2
  description: |
    This project was something I did after university following the specifications of the SWTKG module which I didn't take.
